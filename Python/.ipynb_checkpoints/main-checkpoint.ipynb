{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Librerias\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from dataset import *\n",
    "from EEGNet_model import *\n",
    "from EEGNet_train import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_v3(dir_task,num_class):\n",
    "    \"\"\"\n",
    "    Construye el dataset a partir de la direccion de carpetas y la cantidad de clases\n",
    "    a clasificar. La v3 get_dataset obtiene el train_set, val_set y test_set de forma separada\n",
    "    para el test de independencia de clases\n",
    "    \n",
    "    Argumentos: dir_task(Direccion de carpetas) y num_class(cantidad de clases)\n",
    "    Output: inputs(imagenes) y targets(vector de clases) \n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    train_dir = os.path.join(dir_task, \"train_data\")\n",
    "    val_dir = os.path.join(dir_task, \"val_data\")\n",
    "    test_dir = os.path.join(dir_task, \"test_data\")\n",
    "    \n",
    "    # Sizes\n",
    "    TRAIN_SIZE = 30\n",
    "    VAL_SIZE = 30\n",
    "    BATCH_SIZE = 100\n",
    "\n",
    "    # Training\n",
    "    X_train1 = np.zeros(shape=(TRAIN_SIZE,128, 128, 3))\n",
    "    X_train2 = np.zeros(shape=(TRAIN_SIZE,128, 128, 3))\n",
    "    \n",
    "    fnames_tasks = [os.path.join(train_dir,fname) for fname in os.listdir(train_dir)]\n",
    "    \n",
    "    fnames = [os.path.join(fnames_tasks[0],fname) for fname in os.listdir(fnames_tasks[0])]\n",
    "    for i in range(0,TRAIN_SIZE):\n",
    "        img_path = fnames[i]\n",
    "        img = image.load_img(img_path,target_size=(128,128))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.astype('float32') / 255\n",
    "        X_train1[i] = x\n",
    "    \n",
    "    fnames = [os.path.join(fnames_tasks[1],fname) for fname in os.listdir(fnames_tasks[1])]\n",
    "    for i in range(0,TRAIN_SIZE):\n",
    "        img_path = fnames[i]\n",
    "        img = image.load_img(img_path,target_size=(128,128))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.astype('float32') / 255\n",
    "        X_train2[i] = x\n",
    "    \n",
    "    X_train = np.concatenate((X_train1,X_train2),axis = 0)\n",
    "    \n",
    "    Y_train1 = np.zeros((TRAIN_SIZE,), dtype=np.float64)\n",
    "    Y_train2 = np.ones((TRAIN_SIZE,), dtype=np.float64)\n",
    "    Y_train = np.concatenate((Y_train1,Y_train2))\n",
    "\n",
    "    # Validation \n",
    "    \n",
    "    X_val1 = np.zeros(shape=(VAL_SIZE,128, 128, 3))\n",
    "    X_val2 = np.zeros(shape=(VAL_SIZE,128, 128, 3))\n",
    "    \n",
    "    fnames_tasks = [os.path.join(val_dir,fname) for fname in os.listdir(train_dir)]\n",
    "    \n",
    "    fnames = [os.path.join(fnames_tasks[0],fname) for fname in os.listdir(fnames_tasks[0])]\n",
    "    for i in range(0,VAL_SIZE):\n",
    "        img_path = fnames[i]\n",
    "        img = image.load_img(img_path,target_size=(128,128))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.astype('float32') / 255\n",
    "        X_val1[i] = x\n",
    "    \n",
    "    fnames = [os.path.join(fnames_tasks[1],fname) for fname in os.listdir(fnames_tasks[1])]\n",
    "    for i in range(0,VAL_SIZE):\n",
    "        img_path = fnames[i]\n",
    "        img = image.load_img(img_path,target_size=(128,128))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.astype('float32') / 255\n",
    "        X_val2[i] = x\n",
    "\n",
    "    X_val = np.concatenate((X_val1,X_val2),axis = 0)\n",
    "    \n",
    "    Y_val1 = np.zeros((VAL_SIZE,), dtype=np.float64)\n",
    "    Y_val2 = np.ones((VAL_SIZE,), dtype=np.float64)\n",
    "    Y_val = np.concatenate((Y_val1,Y_val2))\n",
    "\n",
    "    #Testing \n",
    "    \n",
    "    type_class = 'binary'\n",
    "    if (num_class != 2):\n",
    "        type_class = 'sparse'\n",
    "    \n",
    "    datagen_task = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    test_task = datagen_task.flow_from_directory(\n",
    "        test_dir, \n",
    "        batch_size = BATCH_SIZE,\n",
    "        target_size=(128, 128),\n",
    "        class_mode = type_class\n",
    "        )\n",
    "    \n",
    "    num_samples = 0\n",
    "    for i in range(len(test_task)):\n",
    "        num_samples += len(test_task[i][1]) \n",
    "    \n",
    "    X_test = np.zeros(shape=(num_samples, 128, 128, 3))\n",
    "    Y_test = np.zeros(shape=(num_samples))\n",
    "    i=0\n",
    "\n",
    "    for inputs_batch,labels_batch in test_task:\n",
    "        X_test[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] =  inputs_batch\n",
    "        Y_test[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = labels_batch\n",
    "        i += 1\n",
    "        if i * BATCH_SIZE >= num_samples:\n",
    "            break\n",
    "            \n",
    "    return X_train,X_val,X_test,Y_train,Y_val,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kcross_validation_v3(num_class,X_train,X_val,X_test,Y_train,Y_val,Y_test,repetitions):\n",
    "    \"\"\"\n",
    "   \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Per-fold score containers \n",
    "    acc_per_fold = []\n",
    "    val_per_fold = []\n",
    "    lpo = LeavePOut(p=2)\n",
    "    \n",
    "    fold_n = 1\n",
    "    list_channels = np.array([0,1,2,3,4])\n",
    "    step_per_chn_train = 6\n",
    "    step_per_chn_val = 6\n",
    "    \n",
    "    for train,val in lpo.split(list_channels):\n",
    "        \n",
    "        train_index = np.zeros(shape = 0)\n",
    "        val_index = np.zeros(shape = 0)\n",
    "\n",
    "        for i in train:\n",
    "            temp = range(i*step_per_chn_train,(i+1)*step_per_chn_train)\n",
    "            train_index = np.concatenate((train_index,temp))\n",
    "\n",
    "        for k in val:\n",
    "            temp = range(k*step_per_chn_val,(k+1)*step_per_chn_val)\n",
    "            val_index = np.concatenate((val_index,temp))\n",
    "        \n",
    "        train_index = np.concatenate((train_index,train_index+30))\n",
    "        val_index = np.concatenate((val_index,val_index+30))\n",
    "        \n",
    "        train_index = train_index.astype(int)\n",
    "        val_index = val_index.astype(int)\n",
    "        \n",
    "        np.random.shuffle(train_index)\n",
    "        np.random.shuffle(val_index)\n",
    "        \n",
    "        EEGNet = get_EEGNet(num_class)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_n} and Validating with Chn {val[0]+1}')\n",
    "        print(f'Entrenando con canales {train} y validando con canales {val}')\n",
    "\n",
    "        pat = 50\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', mode='max', patience=pat, verbose=1)\n",
    "        model_checkpoint = ModelCheckpoint('./model_checkpoint', verbose=1, save_best_only=True, monitor='val_acc',\n",
    "        mode='max')\n",
    "        \n",
    "        history = EEGNet.fit(X_train[train_index],Y_train[train_index],\n",
    "                             epochs = 50, steps_per_epoch = 2, validation_data = (X_val[val_index],Y_val[val_index]), \n",
    "                             callbacks=[early_stopping, model_checkpoint]\n",
    "                            )\n",
    "        plot_metrics(history,fold_n)\n",
    "    \n",
    "        EGGNetnew = tf.keras.models.load_model('./model_checkpoint')\n",
    "        val_scores = EGGNetnew.evaluate(X_val[val_index],Y_val[val_index],verbose=2)\n",
    "        test_scores = EGGNetnew.evaluate(X_test,Y_test,verbose=2)\n",
    "    \n",
    "        print(f'Val-Score for fold {fold_n}: {EEGNet.metrics_names[0]} of {val_scores[0]}; {EEGNet.metrics_names[1]} of {val_scores[1]*100}%')\n",
    "        print(f'Test-Score for fold {fold_n}: {EEGNet.metrics_names[0]} of {test_scores[0]}; {EEGNet.metrics_names[1]} of {test_scores[1]*100}%')\n",
    "        acc_per_fold.append((val_scores[1],test_scores[1]))\n",
    "        val_per_fold.append(val_scores[1])\n",
    "        \n",
    "         # Increse number of fold\n",
    "        fold_n = fold_n + 1\n",
    "        \n",
    "    val_mean,val_std,test_mean,test_std = print_subject_results(val_per_fold,acc_per_fold,repetitions)\n",
    "    \n",
    "    return val_mean,val_std,test_mean,test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_finales = []\n",
    "num_test = 1\n",
    "num_class = 2\n",
    "repetitions = 1\n",
    "\n",
    "dir_task = r'C:\\Users\\Lenovo\\Documents\\UTEC\\Ciclo 7\\ProyectoCNN\\Python\\Dataset\\Test1'\n",
    "X_train,X_val,X_test,Y_train,Y_val,Y_test = get_dataset_v3(dir_task,num_class)\n",
    "val_mean,val_std,test_mean,test_std = Kcross_validation_v3(num_class,X_train,X_val,X_test,Y_train,Y_val,Y_test,repetitions)\n",
    "resultados_finales.append(f'Val: {val_mean} +- {val_std} // Test: {test_mean} +- {test_std}')\n",
    "    \n",
    "resultados_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
