{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Librerias\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold,RepeatedKFold,train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, optimizers,regularizers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Dense,\\\n",
    "                                    Conv2D,\\\n",
    "                                    BatchNormalization,\\\n",
    "                                    AveragePooling2D, \\\n",
    "                                    MaxPooling2D, \\\n",
    "                                    DepthwiseConv2D, \\\n",
    "                                    Activation, \\\n",
    "                                    Dropout,\\\n",
    "                                    Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cargar data de training y test \n",
    "\n",
    "def get_dataset(dir_task,num_class):\n",
    "    \"\"\"\n",
    "    Construye el dataset a partir de la direccion de carpetas y la cantidad de clases\n",
    "    a clasificar.\n",
    "    \n",
    "    Argumentos: dir_task(Direccion de carpetas) y num_class(cantidad de clases)\n",
    "    Output: inputs(imagenes) y targets(vector de clases) \n",
    "    \"\"\"\n",
    "    \n",
    "    train_dir = os.path.join(dir_task, \"train_data\")\n",
    "    test_dir = os.path.join(dir_task, \"test_data\")\n",
    "    \n",
    "    type_class = 'binary'\n",
    "    if (num_class != 2):\n",
    "        type_class = 'sparse'\n",
    "    \n",
    "    datagen_task = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Train\n",
    "    \n",
    "    data_task = datagen_task.flow_from_directory(\n",
    "        train_dir, \n",
    "        batch_size = 100,\n",
    "        target_size=(128, 128),\n",
    "        class_mode = type_class,\n",
    "        color_mode=\"rgb\"\n",
    "        )\n",
    "    \n",
    "    num_samples = 0\n",
    "    for i in range(len(data_task)):\n",
    "        num_samples += len(data_task[i][1]) \n",
    "\n",
    "\n",
    "    X_train = np.zeros(shape=(num_samples, 128, 128, 3))\n",
    "    Y_train = np.zeros(shape=(num_samples))\n",
    "    i=0\n",
    "\n",
    "    for inputs_batch,labels_batch in data_task:\n",
    "        X_train[i * 100 : (i + 1) * 100] =  inputs_batch\n",
    "        Y_train[i * 100 : (i + 1) * 100] = labels_batch\n",
    "        i += 1\n",
    "        if i * 100 >= num_samples:\n",
    "            break\n",
    "    \n",
    "    # Test\n",
    "    \n",
    "    test_task = datagen_task.flow_from_directory(\n",
    "        test_dir, \n",
    "        batch_size = 100,\n",
    "        target_size=(128, 128),\n",
    "        class_mode = type_class\n",
    "        )\n",
    "    \n",
    "    num_samples = 0\n",
    "    for i in range(len(test_task)):\n",
    "        num_samples += len(test_task[i][1]) \n",
    "    \n",
    "    X_test = np.zeros(shape=(num_samples, 128, 128, 3))\n",
    "    Y_test = np.zeros(shape=(num_samples))\n",
    "    i=0\n",
    "\n",
    "    for inputs_batch,labels_batch in test_task:\n",
    "        X_test[i * 100 : (i + 1) * 100] =  inputs_batch\n",
    "        Y_test[i * 100 : (i + 1) * 100] = labels_batch\n",
    "        i += 1\n",
    "        if i * 100 >= num_samples:\n",
    "            break\n",
    "    \n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_v2(dir_task,num_class):\n",
    "    \"\"\"\n",
    "    Construye el dataset a partir de la direccion de carpetas y la cantidad de clases\n",
    "    a clasificar. La versión 2 get_dataset obtiene las imagenes de las dos clases de forma ordenada por repeticiones/canales\n",
    "    \n",
    "    Argumentos: dir_task(Direccion de carpetas) y num_class(cantidad de clases)\n",
    "    Output: inputs(imagenes) y targets(vector de clases) \n",
    "    \"\"\"\n",
    "    \n",
    "    train_dir = os.path.join(dir_task, \"train_data\")\n",
    "    test_dir = os.path.join(dir_task, \"test_data\")\n",
    "    \n",
    "    # Training\n",
    "    \n",
    "    X_train1 = np.zeros(shape=(250,128, 128, 3))\n",
    "    X_train2 = np.zeros(shape=(250,128, 128, 3))\n",
    "    X_train3 = np.zeros(shape=(250,128, 128, 3))\n",
    "    \n",
    "    fnames_tasks = [os.path.join(train_dir,fname) for fname in os.listdir(train_dir)]\n",
    "    \n",
    "    fnames = [os.path.join(fnames_tasks[0],fname) for fname in os.listdir(fnames_tasks[0])]\n",
    "    for i in range(0,250):\n",
    "        img_path = fnames[i]\n",
    "        img = image.load_img(img_path,target_size=(128,128))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.astype('float32') / 255\n",
    "        X_train1[i] = x\n",
    "    \n",
    "    fnames = [os.path.join(fnames_tasks[1],fname) for fname in os.listdir(fnames_tasks[1])]\n",
    "    for i in range(0,250):\n",
    "        img_path = fnames[i]\n",
    "        img = image.load_img(img_path,target_size=(128,128))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.astype('float32') / 255\n",
    "        X_train2[i] = x\n",
    "    \n",
    "    fnames = [os.path.join(fnames_tasks[2],fname) for fname in os.listdir(fnames_tasks[2])]\n",
    "    for i in range(0,250):\n",
    "        img_path = fnames[i]\n",
    "        img = image.load_img(img_path,target_size=(128,128))\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.astype('float32') / 255\n",
    "        X_train3[i] = x\n",
    "   \n",
    "    X_train = np.concatenate((X_train1,X_train2,X_train3),axis = 0)\n",
    "    \n",
    "    Y_task1 = np.zeros((300,), dtype=np.float64)\n",
    "    Y_task2 = np.ones((300,), dtype=np.float64)\n",
    "    Y_task3 = 2*np.ones((300,), dtype=np.float64)\n",
    "    \n",
    "    Y_train = np.concatenate((Y_task1,Y_task2,Y_task3))\n",
    "    # Testing\n",
    "    \n",
    "    type_class = 'binary'\n",
    "    if (num_class != 2):\n",
    "        type_class = 'sparse'\n",
    "    \n",
    "    datagen_task = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    test_task = datagen_task.flow_from_directory(\n",
    "        test_dir, \n",
    "        batch_size = 100,\n",
    "        target_size=(128, 128),\n",
    "        class_mode = type_class\n",
    "        )\n",
    "    \n",
    "    num_samples = 0\n",
    "    for i in range(len(test_task)):\n",
    "        num_samples += len(test_task[i][1]) \n",
    "    \n",
    "    X_test = np.zeros(shape=(num_samples, 128, 128, 3))\n",
    "    Y_test = np.zeros(shape=(num_samples))\n",
    "    i=0\n",
    "\n",
    "    for inputs_batch,labels_batch in test_task:\n",
    "        X_test[i * 100 : (i + 1) * 100] =  inputs_batch\n",
    "        Y_test[i * 100 : (i + 1) * 100] = labels_batch\n",
    "        i += 1\n",
    "        if i * 100 >= num_samples:\n",
    "            break\n",
    "            \n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEGNet_model(num_class):\n",
    "    \"\"\"\n",
    "    Construye una EEGNet utilizando Tensorflow de forma secuencial.\n",
    "    \n",
    "    Argumentos: num_class\n",
    "    Output: EEGNet como modelo de Tensorflow.keras\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    EEGNet = tf.keras.Sequential()\n",
    "\n",
    "    # Block1\n",
    "    regularizers.l2(1e-4)\n",
    "    EEGNet.add(Conv2D(4, (1, 125),\n",
    "                        padding='same',\n",
    "                        use_bias=False,\n",
    "                        name='tfconv',input_shape = (128,128,3)))\n",
    "    EEGNet.add(BatchNormalization(axis=-1))\n",
    "    EEGNet.add(DepthwiseConv2D((6, 1),\n",
    "                             use_bias=False,\n",
    "                             depth_multiplier=2,\n",
    "                             depthwise_constraint=max_norm(1.),\n",
    "                             name='sconv'))\n",
    "    EEGNet.add(BatchNormalization(axis=-1))\n",
    "    EEGNet.add(Activation('elu'))\n",
    "    EEGNet.add(AveragePooling2D((1, 4)))\n",
    "    EEGNet.add(Dropout(0.5))\n",
    "\n",
    "    # Block 2\n",
    "\n",
    "    EEGNet.add(Conv2D(8, (1, 32),\n",
    "                             padding='same',\n",
    "                             use_bias=False,\n",
    "                             name='fs',\n",
    "                             kernel_regularizer='l2'\n",
    "                     ))\n",
    "    EEGNet.add(BatchNormalization(axis=-1))\n",
    "    EEGNet.add(Activation('elu'))\n",
    "    EEGNet.add(AveragePooling2D((1, 8)))\n",
    "    EEGNet.add(Dropout(0.5))\n",
    "\n",
    "    # Output\n",
    "\n",
    "    EEGNet.add(Flatten(name='flatten'))\n",
    "\n",
    "    EEGNet.add(Dense(num_class,\n",
    "                  name='dense',\n",
    "                  kernel_constraint=max_norm(0.25)))\n",
    "    EEGNet.add(Activation('softmax', name='softmax'))\n",
    "\n",
    "    return EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compile(model: tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Compila el modelo con un optimizador Adam (lr = 0.001), loss categorico y como metrica el accuracy\n",
    "    \n",
    "    Argumentos: CNN como modelo\n",
    "    Output: Modelo compilado\n",
    "    \"\"\"\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EEGNet(num_class):\n",
    "    \"\"\"\n",
    "    Crea y compila una EEGNet lista para entrenarla y clasificar. Se adapta según la \n",
    "    cantidad de clases\n",
    "    \n",
    "    Argumentos: num_class\n",
    "    Output: modelo listo \n",
    "    \"\"\"\n",
    "    \n",
    "    model = EEGNet_model(num_class)\n",
    "    model = get_compile(model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history,fold):\n",
    "    plt.title('Train Accuracy vs Val Accuracy Fold:' + str(fold))\n",
    "    plt.plot(history.history['acc'], label='Train Accuracy Fold ', color='black')\n",
    "    plt.plot(history.history['val_acc'], label='Val Accuracy Fold ', color='red', linestyle = \"dashdot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history,fold):\n",
    "    plt.title('Train Loss vs Val Loss Fold:' + str(fold))\n",
    "    plt.plot(history.history['loss'], label='Train Loss Fold ', color='black')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss Fold ', color='red', linestyle = \"dashdot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_metrics(history,fold):\n",
    "    plot_acc(history,fold)\n",
    "    plot_loss(history,fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_subject_results(val_per_fold,acc_per_fold,repetitions):\n",
    "    \"\"\"\n",
    "    Imprime los accuracy conseguido en cada Fold y calcula el acc y loss promedio de los folds de cada run\n",
    "    \n",
    "    Argumentos: Vector de loss dim(folds * repeticiones)\n",
    "                Vector de accuracy \n",
    "    Output: Acc promedio final\n",
    "            Std promedio final\n",
    "    \"\"\"\n",
    "    \n",
    "    test_score_final = []\n",
    "    val_score_final = []\n",
    "    print('******************')\n",
    "    print('Precision por run')\n",
    "    print('**************************')\n",
    "    print('*Val_acc --------Test_acc*')\n",
    "    for i in range(0,repetitions):\n",
    "        max_per_fold = max(acc_per_fold[0*i:5*(i+1)])\n",
    "        test_score_final.append(max_per_fold[1])\n",
    "        val_score_final.append(np.mean(val_per_fold[0*i:5*(i+1)]))\n",
    "\n",
    "    val_mean = np.mean(val_score_final)    \n",
    "    val_std = np.std(val_score_final)\n",
    "    test_mean = np.mean(test_score_final)\n",
    "    test_std = np.std(test_score_final)\n",
    "        \n",
    "    print(f'Val Accuracy:{val_mean*100} +- {val_std*100}')\n",
    "    print(f'Test Accuracy:{test_mean*100} +- {test_std*100}')\n",
    "    \n",
    "    return val_mean,val_std,test_mean,test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kcross_validation(num_class,X_train,X_test,Y_train,Y_test,repetitions):\n",
    "    \"\"\"\n",
    "    Aplica Repeated K-cross validation considerando la repeticiones deseadas\n",
    "    \n",
    "    Argumentos: num_class\n",
    "                inputs(imagenes)\n",
    "                targets(clases)\n",
    "                repetitions\n",
    "                \n",
    "    Output: val_mean,val_std,test_mean,test_std\n",
    "    \"\"\"\n",
    "    \n",
    "    # Per-fold score containers \n",
    "    acc_per_fold = []\n",
    "    val_per_fold = []\n",
    "    kfold = RepeatedKFold(n_splits = 5, n_repeats = repetitions)\n",
    "    fold_n = 1\n",
    "    \n",
    "    for train,val in kfold.split(X_train,Y_train):\n",
    "        EEGNet = get_EEGNet(num_class)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_n} ...')\n",
    "\n",
    "        pat = 25\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', mode='max', patience=pat, verbose=1)\n",
    "        model_checkpoint = ModelCheckpoint('./model_checkpoint', verbose=1, save_best_only=True, monitor='val_acc',\n",
    "        mode='max')\n",
    "        \n",
    "        history = EEGNet.fit(X_train[train] , Y_train[train], \n",
    "                             epochs = 50, steps_per_epoch = 2, validation_data = (X_train[val],Y_train[val]), \n",
    "                             callbacks=[early_stopping, model_checkpoint]\n",
    "                            )\n",
    "        plot_metrics(history,fold_n)\n",
    "    \n",
    "        EGGNetnew = tf.keras.models.load_model('./model_checkpoint')\n",
    "        val_scores = EGGNetnew.evaluate(X_train[val],Y_train[val],verbose=0)\n",
    "        test_scores = EGGNetnew.evaluate(X_test,Y_test,verbose=0)\n",
    "\n",
    "        print(f'Val-Score for fold {fold_n}: {EEGNet.metrics_names[0]} of {val_scores[0]}; {EEGNet.metrics_names[1]} of {val_scores[1]*100}%')\n",
    "        print(f'Test-Score for fold {fold_n}: {EEGNet.metrics_names[0]} of {test_scores[0]}; {EEGNet.metrics_names[1]} of {test_scores[1]*100}%')\n",
    "        acc_per_fold.append((val_scores[1],test_scores[1]))\n",
    "        val_per_fold.append(val_scores[1])\n",
    "\n",
    "        # Increse number of fold\n",
    "\n",
    "        fold_n = fold_n + 1\n",
    "    \n",
    "    val_mean,val_std,test_mean,test_std = print_subject_results(val_per_fold,acc_per_fold,repetitions)\n",
    "    \n",
    "    return val_mean,val_std,test_mean,test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kcross_validation_v2(num_class,X_train,X_test,Y_train,Y_test,repetitions):\n",
    "    \"\"\"\n",
    "    Aplica Repeated K-cross validation considerando la repeticiones deseadas. Separa training y validation por canales \n",
    "    donde se valida con 1 canal. El canal utilizado en testeo se obtiene ya desde get_dataset\n",
    "    \n",
    "    Argumentos: num_class\n",
    "                inputs(imagenes)\n",
    "                targets(clases)\n",
    "                repetitions\n",
    "                \n",
    "    Output: val_mean,val_std,test_mean,test_std\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Per-fold score containers \n",
    "    acc_per_fold = []\n",
    "    val_per_fold = []\n",
    "    kfold = RepeatedKFold(n_splits = 5, n_repeats = repetitions)\n",
    "    \n",
    "    fold_n = 1\n",
    "    list_channels = np.array([0,1,2,3,4])\n",
    "    step_per_chn = 50\n",
    "    \n",
    "    for train,val in kfold.split(list_channels):\n",
    "        \n",
    "        train_index = np.zeros(shape = 0)\n",
    "        val_index = np.zeros(shape = 0)\n",
    "\n",
    "        for i in train:\n",
    "            temp = range(i*step_per_chn,(i+1)*step_per_chn)\n",
    "            train_index = np.concatenate((train_index,temp))\n",
    "\n",
    "        for k in val:\n",
    "            temp = range(k*step_per_chn,(k+1)*step_per_chn)\n",
    "            val_index = np.concatenate((val_index,temp))\n",
    "        \n",
    "        train_index = np.concatenate((train_index,train_index+250,train_index+500))\n",
    "        val_index = np.concatenate((val_index,val_index+250,val_index+500))\n",
    "\n",
    "        np.random.shuffle(train_index)\n",
    "        np.random.shuffle(val_index)\n",
    "        \n",
    "        train_index = train_index.astype(int)\n",
    "        val_index = val_index.astype(int)\n",
    "        \n",
    "        EEGNet = get_EEGNet(num_class)\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_n} and Validating with Chn {val[0]+1}')\n",
    "\n",
    "        pat = 50\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', mode='max', patience=pat, verbose=1)\n",
    "        model_checkpoint = ModelCheckpoint('./model_checkpoint', verbose=1, save_best_only=True, monitor='val_acc',\n",
    "        mode='max')\n",
    "        \n",
    "        history = EEGNet.fit(X_train[train_index] , Y_train[train_index], \n",
    "                             epochs = 100, steps_per_epoch = 5, validation_data = (X_train[val_index],Y_train[val_index]), \n",
    "                             callbacks=[early_stopping, model_checkpoint]\n",
    "                            )\n",
    "        plot_metrics(history,fold_n)\n",
    "    \n",
    "        EGGNetnew = tf.keras.models.load_model('./model_checkpoint')\n",
    "        val_scores = EGGNetnew.evaluate(X_train[val_index],Y_train[val_index],verbose=0)\n",
    "        test_scores = EGGNetnew.evaluate(X_test,Y_test,verbose=0)\n",
    "    \n",
    "        print(f'Val-Score for fold {fold_n}: {EEGNet.metrics_names[0]} of {val_scores[0]}; {EEGNet.metrics_names[1]} of {val_scores[1]*100}%')\n",
    "        print(f'Test-Score for fold {fold_n}: {EEGNet.metrics_names[0]} of {test_scores[0]}; {EEGNet.metrics_names[1]} of {test_scores[1]*100}%')\n",
    "        acc_per_fold.append((val_scores[1],test_scores[1]))\n",
    "        val_per_fold.append(val_scores[1])\n",
    "        \n",
    "         # Increse number of fold\n",
    "        fold_n = fold_n + 1\n",
    "        \n",
    "    val_mean,val_std,test_mean,test_std = print_subject_results(val_per_fold,acc_per_fold,repetitions)\n",
    "    \n",
    "    return val_mean,val_std,test_mean,test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_finales = []\n",
    "num_test = 1\n",
    "num_class = 3\n",
    "repetitions = 1\n",
    "\n",
    "for i in range(num_test):\n",
    "    dir_task = r'C:\\Users\\Lenovo\\Documents\\UTEC\\Ciclo 7\\ProyectoCNN\\Python\\Dataset\\Test' + str(i+1)\n",
    "    X_train,X_test,Y_train,Y_test = get_dataset_v2(dir_task,num_class)\n",
    "    val_mean,val_std,test_mean,test_std = Kcross_validation_v2(num_class,X_train,X_test,Y_train,Y_test,repetitions)\n",
    "    resultados_finales.append(f'Val: {val_mean} +- {val_std} // Test: {test_mean} +- {test_std}')\n",
    "    \n",
    "resultados_finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
